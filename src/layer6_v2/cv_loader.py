"""
CV Loader - Load pre-split role data from data/master-cv/

Reads the static role files and metadata created during setup.
The master CV is split ONCE into static files:
- data/master-cv/roles/*.md (one file per company/role)
- data/master-cv/role_metadata.json (structured metadata)

This approach:
1. Avoids re-parsing master CV on every run
2. Allows manual curation of role files
3. Makes it easy to add/remove bullets per role
4. Provides structured metadata for intelligent selection

Enhanced Format Support (2024-12):
- Supports variant-based achievement structure
- Each achievement can have multiple variants (Technical, Architecture, Impact, etc.)
- Uses VariantParser for enhanced format, falls back to simple bullets

MongoDB Integration (Phase 5 - JD Annotation System):
- Optional MongoDB storage via MasterCVStore
- Automatic file fallback for local development
- Real-time sync: changes in MongoDB immediately available to runner
"""

import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Set, TYPE_CHECKING
from dataclasses import dataclass, field
from src.common.logger import get_logger
from src.common.utils import coerce_to_list, coerce_to_dict, safe_get_nested

# Import enhanced format support
from src.layer6_v2.variant_parser import (
    VariantParser,
    EnhancedRoleData,
    Achievement,
    AchievementVariant,
)

if TYPE_CHECKING:
    from src.common.master_cv_store import MasterCVStore


@dataclass
class RoleData:
    """Data for a single role/company from the master CV."""

    id: str
    company: str
    title: str
    location: str
    period: str
    start_year: int
    end_year: Optional[int]
    is_current: bool
    duration_years: int
    industry: str
    team_size: str
    primary_competencies: List[str]
    keywords: List[str]

    # Content loaded from role file
    achievements: List[str] = field(default_factory=list)
    hard_skills: List[str] = field(default_factory=list)
    soft_skills: List[str] = field(default_factory=list)
    raw_content: str = ""

    # Enhanced format support (populated when using enhanced role files)
    enhanced_data: Optional[EnhancedRoleData] = None

    @property
    def bullet_count(self) -> int:
        """Return count of achievements (computed, not stored)."""
        return len(self.achievements)

    @property
    def has_variants(self) -> bool:
        """Check if this role has enhanced variant data."""
        return self.enhanced_data is not None and len(self.enhanced_data.achievements) > 0

    @property
    def variant_count(self) -> int:
        """Return total number of variants if enhanced data available."""
        if self.enhanced_data:
            return self.enhanced_data.total_variants
        return 0

    def get_achievement_variants(self, achievement_index: int) -> Optional[Achievement]:
        """
        Get structured achievement with variants by index (0-based).

        Args:
            achievement_index: Index of the achievement

        Returns:
            Achievement object with variants, or None if not available
        """
        if not self.enhanced_data:
            return None
        if 0 <= achievement_index < len(self.enhanced_data.achievements):
            return self.enhanced_data.achievements[achievement_index]
        return None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for state/serialization."""
        return {
            "id": self.id,
            "company": self.company,
            "title": self.title,
            "location": self.location,
            "period": self.period,
            "start_year": self.start_year,
            "end_year": self.end_year,
            "is_current": self.is_current,
            "duration_years": self.duration_years,
            "industry": self.industry,
            "team_size": self.team_size,
            "bullet_count": self.bullet_count,  # Computed property
            "primary_competencies": self.primary_competencies,
            "keywords": self.keywords,
            "achievements": self.achievements,
            "hard_skills": self.hard_skills,
            "soft_skills": self.soft_skills,
            "has_variants": self.has_variants,
            "variant_count": self.variant_count,
        }


@dataclass
class CandidateData:
    """
    Candidate profile data from master CV metadata.

    NOTE: profile and core_skills are NOT stored here - they are
    dynamically generated by the Header Generator after stitching,
    tailored to the target role category and JD requirements.
    """

    name: str
    title_base: str  # Base title, will be tailored per application
    email: str
    phone: str
    linkedin: str
    nationality: str
    languages: List[str]
    education_masters: str
    education_bachelors: str
    certifications: List[str]
    years_experience: int

    # Roles loaded from individual files
    roles: List[RoleData] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for state/serialization."""
        return {
            "name": self.name,
            "title_base": self.title_base,
            "email": self.email,
            "phone": self.phone,
            "linkedin": self.linkedin,
            "nationality": self.nationality,
            "languages": self.languages,
            "education_masters": self.education_masters,
            "education_bachelors": self.education_bachelors,
            "certifications": self.certifications,
            "years_experience": self.years_experience,
            "roles": [r.to_dict() for r in self.roles],
        }


class CVLoader:
    """
    Load pre-split CV data from data/master-cv/.

    This class reads the static role files and metadata that were
    created during initial setup. No dynamic parsing needed.

    Enhanced Format Support:
    When role files use the variant-based format (with ### Achievement N:
    headers), the loader automatically parses variants using VariantParser
    and populates the enhanced_data field on each RoleData.

    Usage:
        loader = CVLoader()
        candidate = loader.load()

        # Access all roles
        for role in candidate.roles:
            print(f"{role.company}: {len(role.achievements)} bullets")
            if role.has_variants:
                print(f"  Enhanced: {role.variant_count} variants available")

        # Filter by competency
        leadership_roles = loader.filter_by_competency("leadership")

        # Get enhanced role data for variant selection
        enhanced_roles = loader.get_enhanced_roles()
    """

    DEFAULT_DATA_PATH = Path("data/master-cv")

    def __init__(
        self,
        data_path: Optional[Path] = None,
        use_enhanced: bool = True,
        use_mongodb: bool = False,
        mongo_store: Optional["MasterCVStore"] = None,
    ):
        """
        Initialize the CV loader.

        Args:
            data_path: Path to master-cv data directory.
                       Defaults to data/master-cv/
            use_enhanced: Whether to parse enhanced variant format (default True)
            use_mongodb: Whether to try MongoDB first (default False for backward compat)
            mongo_store: Optional pre-configured MasterCVStore instance
        """
        self.data_path = data_path or self.DEFAULT_DATA_PATH
        self.metadata_path = self.data_path / "role_metadata.json"
        self.roles_path = self.data_path / "roles"
        self._candidate: Optional[CandidateData] = None
        self._enhanced_roles: Optional[Dict[str, EnhancedRoleData]] = None
        self._use_enhanced = use_enhanced
        self._variant_parser = VariantParser() if use_enhanced else None
        self._logger = get_logger(__name__)

        # MongoDB integration (Phase 5)
        self._use_mongodb = use_mongodb
        self._mongo_store: Optional["MasterCVStore"] = mongo_store
        self._loaded_from_mongodb = False

        if use_mongodb and mongo_store is None:
            try:
                from src.common.master_cv_store import MasterCVStore
                self._mongo_store = MasterCVStore(use_mongodb=True, data_dir=self.data_path)
                self._logger.info("âœ… CVLoader initialized with MongoDB support (will use CV Editor data)")
            except Exception as e:
                self._logger.warning(f"âš ï¸ MongoDB unavailable for CVLoader, using local files: {e}")
                self._use_mongodb = False
        elif not use_mongodb:
            self._logger.info("ðŸ“ CVLoader using local files (MongoDB disabled via config)")

    def load(self) -> CandidateData:
        """
        Load all CV data from MongoDB or pre-split files.

        MongoDB is tried first if use_mongodb=True. Falls back to file-based
        loading if MongoDB is unavailable or data not found.

        Returns:
            CandidateData with all roles populated

        Raises:
            FileNotFoundError: If metadata or role files missing (and MongoDB unavailable)
            ValueError: If metadata is malformed
        """
        if self._candidate is not None:
            return self._candidate

        # Try MongoDB first if enabled
        if self._use_mongodb and self._mongo_store:
            try:
                candidate = self._load_from_mongodb()
                if candidate:
                    self._candidate = candidate
                    self._loaded_from_mongodb = True
                    self._logger.info(
                        f"âœ… Loaded {len(self._candidate.roles)} roles from MongoDB (CV Editor data)"
                    )
                    return self._candidate
            except Exception as e:
                self._logger.warning(f"MongoDB load failed, falling back to files: {e}")

        # Fall back to file-based loading
        return self._load_from_files()

    def _load_from_mongodb(self) -> Optional[CandidateData]:
        """
        Load CV data from MongoDB via MasterCVStore.

        Returns:
            CandidateData if successful, None if data not found
        """
        if not self._mongo_store:
            return None

        metadata = self._mongo_store.get_metadata()
        if not metadata:
            self._logger.debug("No metadata found in MongoDB")
            return None

        # Build candidate data from MongoDB metadata
        candidate_meta = metadata.get("candidate", {})
        if not candidate_meta:
            self._logger.warning("MongoDB metadata missing 'candidate' field")
            return None

        # Use defensive type coercion for nested dict access from MongoDB
        # This handles cases where contact/education may be None or wrong type
        contact = coerce_to_dict(candidate_meta.get("contact"))
        education = coerce_to_dict(candidate_meta.get("education"))

        candidate = CandidateData(
            name=candidate_meta.get("name", ""),
            title_base=candidate_meta.get("title_base", ""),
            email=contact.get("email", ""),
            phone=contact.get("phone", ""),
            linkedin=contact.get("linkedin", ""),
            nationality=contact.get("nationality", ""),
            languages=coerce_to_list(candidate_meta.get("languages")),
            education_masters=education.get("masters", ""),
            education_bachelors=education.get("bachelors", ""),
            certifications=coerce_to_list(candidate_meta.get("certifications")),
            years_experience=candidate_meta.get("years_experience", 0),
            roles=[],
        )

        # Load each role
        for role_meta in metadata.get("roles", []):
            role = self._load_role_from_mongodb_or_file(role_meta)
            if role:
                candidate.roles.append(role)

        return candidate

    def _load_role_from_mongodb_or_file(self, role_meta: Dict[str, Any]) -> Optional[RoleData]:
        """
        Load a role, trying MongoDB first then falling back to file.

        Args:
            role_meta: Role metadata from the metadata document

        Returns:
            RoleData or None if not found
        """
        role_id = role_meta.get("id", "")

        # Try MongoDB first
        if self._mongo_store:
            role_doc = self._mongo_store.get_role(role_id)
            if role_doc and role_doc.get("markdown_content"):
                return self._build_role_from_content(
                    role_meta,
                    role_doc["markdown_content"],
                    source="mongodb"
                )

        # Fall back to file
        return self._load_role(role_meta)

    def _build_role_from_content(
        self,
        role_meta: Dict[str, Any],
        content: str,
        source: str = "file"
    ) -> RoleData:
        """
        Build RoleData from content string (shared by file and MongoDB paths).

        Args:
            role_meta: Role metadata
            content: Markdown content
            source: Source identifier for logging

        Returns:
            Populated RoleData
        """
        # Try to parse as enhanced format first
        enhanced_data = None
        role_id = role_meta["id"]
        if self._use_enhanced and self._variant_parser:
            try:
                # Parse from content string rather than file
                enhanced_data = self._variant_parser.parse_content(content, role_id=role_id)
                # Cache for later use
                if self._enhanced_roles is None:
                    self._enhanced_roles = {}
                self._enhanced_roles[role_id] = enhanced_data
            except Exception as e:
                self._logger.warning(
                    f"Failed to parse enhanced format for {role_id} ({source}): {e}"
                )
                enhanced_data = None

        # Parse achievements - use enhanced data if available
        if enhanced_data and enhanced_data.achievements:
            achievements = [a.core_fact for a in enhanced_data.achievements]
            hard_skills = enhanced_data.hard_skills
            soft_skills = enhanced_data.soft_skills
        else:
            achievements = self._parse_achievements(content)
            hard_skills, soft_skills = self._parse_skills(content)

        return RoleData(
            id=role_meta["id"],
            company=role_meta["company"],
            title=role_meta["title"],
            location=role_meta.get("location", ""),
            period=role_meta["period"],
            start_year=role_meta["start_year"],
            end_year=role_meta["end_year"],
            is_current=role_meta["is_current"],
            duration_years=role_meta["duration_years"],
            industry=role_meta["industry"],
            team_size=role_meta["team_size"],
            primary_competencies=role_meta["primary_competencies"],
            keywords=role_meta["keywords"],
            achievements=achievements,
            hard_skills=hard_skills,
            soft_skills=soft_skills,
            raw_content=content,
            enhanced_data=enhanced_data,
        )

    def _load_from_files(self) -> CandidateData:
        """
        Load CV data from local files (original file-based implementation).

        Returns:
            CandidateData with all roles populated

        Raises:
            FileNotFoundError: If metadata or role files missing
        """
        # Load metadata
        if not self.metadata_path.exists():
            raise FileNotFoundError(
                f"Role metadata not found at {self.metadata_path}. "
                "Run the CV split setup first."
            )

        with open(self.metadata_path, "r") as f:
            metadata = json.load(f)

        # Build candidate data (static fields only - profile/skills generated later)
        # Use defensive type coercion for nested dict access from file
        candidate_meta = metadata["candidate"]
        contact = coerce_to_dict(candidate_meta.get("contact"))
        education = coerce_to_dict(candidate_meta.get("education"))

        self._candidate = CandidateData(
            name=candidate_meta.get("name", ""),
            title_base=candidate_meta.get("title_base", ""),
            email=contact.get("email", ""),
            phone=contact.get("phone", ""),
            linkedin=contact.get("linkedin", ""),
            nationality=contact.get("nationality", ""),
            languages=coerce_to_list(candidate_meta.get("languages")),
            education_masters=education.get("masters", ""),
            education_bachelors=education.get("bachelors", ""),
            certifications=coerce_to_list(candidate_meta.get("certifications")),
            years_experience=candidate_meta.get("years_experience", 0),
            roles=[],
        )

        # Load each role file
        for role_meta in metadata["roles"]:
            role = self._load_role(role_meta)
            self._candidate.roles.append(role)

        self._logger.info(f"Loaded {len(self._candidate.roles)} roles from files")
        return self._candidate

    def _load_role(self, role_meta: Dict[str, Any]) -> RoleData:
        """Load a single role from its markdown file."""
        role_file = self.data_path / role_meta["file"]

        if not role_file.exists():
            raise FileNotFoundError(f"Role file not found: {role_file}")

        with open(role_file, "r") as f:
            content = f.read()

        # Try to parse as enhanced format first
        enhanced_data = None
        if self._use_enhanced and self._variant_parser:
            try:
                enhanced_data = self._variant_parser.parse_role_file(role_file)
                # Cache for later use
                if self._enhanced_roles is None:
                    self._enhanced_roles = {}
                self._enhanced_roles[role_meta["id"]] = enhanced_data
            except Exception as e:
                self._logger.warning(f"Failed to parse enhanced format for {role_file}: {e}")
                enhanced_data = None

        # Parse achievements - use enhanced data if available
        if enhanced_data and enhanced_data.achievements:
            # Extract core facts as achievements for backward compatibility
            achievements = [a.core_fact for a in enhanced_data.achievements]
            hard_skills = enhanced_data.hard_skills
            soft_skills = enhanced_data.soft_skills
        else:
            # Fall back to simple bullet parsing
            achievements = self._parse_achievements(content)
            hard_skills, soft_skills = self._parse_skills(content)

        return RoleData(
            id=role_meta["id"],
            company=role_meta["company"],
            title=role_meta["title"],
            location=role_meta["location"],
            period=role_meta["period"],
            start_year=role_meta["start_year"],
            end_year=role_meta["end_year"],
            is_current=role_meta["is_current"],
            duration_years=role_meta["duration_years"],
            industry=role_meta["industry"],
            team_size=role_meta["team_size"],
            primary_competencies=role_meta["primary_competencies"],
            keywords=role_meta["keywords"],
            achievements=achievements,
            hard_skills=hard_skills,
            soft_skills=soft_skills,
            raw_content=content,
            enhanced_data=enhanced_data,
        )

    def _parse_achievements(self, content: str) -> List[str]:
        """Parse achievement bullets from role file content."""
        achievements = []
        in_achievements = False

        for line in content.split("\n"):
            line = line.strip()

            if line == "## Achievements":
                in_achievements = True
                continue
            elif line.startswith("## "):
                in_achievements = False
                continue

            if in_achievements and line.startswith("â€¢"):
                # Remove bullet point and clean up
                achievement = line[1:].strip()
                if achievement:
                    achievements.append(achievement)

        return achievements

    def _parse_skills(self, content: str) -> tuple[List[str], List[str]]:
        """Parse hard and soft skills from role file content."""
        hard_skills = []
        soft_skills = []

        for line in content.split("\n"):
            line = line.strip()

            if line.startswith("**Hard Skills**:"):
                skills_str = line.replace("**Hard Skills**:", "").strip()
                hard_skills = [s.strip() for s in skills_str.split(",") if s.strip()]
            elif line.startswith("**Soft Skills**:"):
                skills_str = line.replace("**Soft Skills**:", "").strip()
                soft_skills = [s.strip() for s in skills_str.split(",") if s.strip()]

        return hard_skills, soft_skills

    def filter_by_competency(self, competency: str) -> List[RoleData]:
        """
        Get roles where the given competency is primary.

        Args:
            competency: One of "leadership", "architecture", "delivery", "process"

        Returns:
            List of roles with that competency as primary
        """
        if self._candidate is None:
            self.load()

        return [
            role for role in self._candidate.roles
            if competency in role.primary_competencies
        ]

    def filter_by_industry(self, industry: str) -> List[RoleData]:
        """Get roles in a specific industry."""
        if self._candidate is None:
            self.load()

        return [
            role for role in self._candidate.roles
            if industry.lower() in role.industry.lower()
        ]

    def get_current_role(self) -> Optional[RoleData]:
        """Get the current (most recent) role."""
        if self._candidate is None:
            self.load()

        for role in self._candidate.roles:
            if role.is_current:
                return role
        return None

    def get_all_keywords(self) -> List[str]:
        """Get deduplicated list of all keywords across roles."""
        if self._candidate is None:
            self.load()

        keywords = set()
        for role in self._candidate.roles:
            keywords.update(role.keywords)

        return sorted(keywords)

    def get_total_bullets(self) -> int:
        """Get total number of achievement bullets across all roles."""
        if self._candidate is None:
            self.load()

        return sum(len(role.achievements) for role in self._candidate.roles)

    def get_all_hard_skills(self) -> List[str]:
        """
        Get deduplicated list of all hard skills across roles.

        These are the ONLY technical skills that should appear in generated CVs.
        Any skill not in this list is a hallucination.

        Returns:
            Sorted list of unique hard skills from master-cv
        """
        if self._candidate is None:
            self.load()

        skills = set()
        for role in self._candidate.roles:
            # Normalize skills to lowercase for deduplication
            for skill in role.hard_skills:
                skills.add(skill.strip())

        return sorted(skills, key=str.lower)

    def get_all_soft_skills(self) -> List[str]:
        """
        Get deduplicated list of all soft skills across roles.

        Returns:
            Sorted list of unique soft skills from master-cv
        """
        if self._candidate is None:
            self.load()

        skills = set()
        for role in self._candidate.roles:
            for skill in role.soft_skills:
                skills.add(skill.strip())

        return sorted(skills, key=str.lower)

    def get_skill_whitelist(self) -> Dict[str, List[str]]:
        """
        Get all skills as a whitelist for CV generation.

        This prevents hallucinations by ensuring only skills that
        actually appear in the master-cv are included.

        Returns:
            Dict with 'hard_skills' and 'soft_skills' lists
        """
        return {
            "hard_skills": self.get_all_hard_skills(),
            "soft_skills": self.get_all_soft_skills(),
        }

    def skill_exists(self, skill: str) -> bool:
        """
        Check if a skill exists in the master-cv.

        Used for validation to prevent hallucinated skills.

        Args:
            skill: Skill name to check (case-insensitive)

        Returns:
            True if skill exists in hard_skills or soft_skills
        """
        skill_lower = skill.lower()
        all_skills = self.get_all_hard_skills() + self.get_all_soft_skills()
        return any(s.lower() == skill_lower for s in all_skills)

    # =========================================================================
    # ENHANCED FORMAT METHODS
    # =========================================================================

    def get_enhanced_roles(self) -> Dict[str, EnhancedRoleData]:
        """
        Get all enhanced role data for variant selection.

        This method returns the parsed enhanced format data that can be
        used with VariantSelector for intelligent bullet selection.

        Returns:
            Dictionary mapping role_id to EnhancedRoleData

        Raises:
            ValueError: If enhanced parsing is disabled or failed
        """
        if self._candidate is None:
            self.load()

        if not self._use_enhanced:
            raise ValueError("Enhanced parsing is disabled. Initialize with use_enhanced=True")

        if self._enhanced_roles is None:
            raise ValueError("No enhanced role data available. Role files may not be in enhanced format.")

        return self._enhanced_roles

    def get_enhanced_role(self, role_id: str) -> Optional[EnhancedRoleData]:
        """
        Get enhanced data for a specific role.

        Args:
            role_id: The role ID (e.g., "01_seven_one_entertainment")

        Returns:
            EnhancedRoleData for the role, or None if not available
        """
        if self._candidate is None:
            self.load()

        if self._enhanced_roles:
            return self._enhanced_roles.get(role_id)
        return None

    def has_enhanced_data(self) -> bool:
        """
        Check if enhanced variant data is available.

        Returns:
            True if at least one role has enhanced data
        """
        if self._candidate is None:
            self.load()

        return bool(self._enhanced_roles)

    def get_total_variants(self) -> int:
        """
        Get total number of variants across all roles.

        Returns:
            Total variant count, or 0 if no enhanced data
        """
        if not self.has_enhanced_data():
            return 0

        return sum(
            role.total_variants
            for role in self._enhanced_roles.values()
        )

    def get_all_achievement_keywords(self) -> List[str]:
        """
        Get all unique keywords from all achievements across all roles.

        These are ATS-optimized keywords extracted from enhanced role files.

        Returns:
            Sorted list of unique keywords
        """
        if not self.has_enhanced_data():
            return []

        keywords = set()
        for role in self._enhanced_roles.values():
            keywords.update(role.all_keywords)

        return sorted(keywords)

    def get_roles_with_variants(self) -> List[RoleData]:
        """
        Get only roles that have enhanced variant data.

        Returns:
            List of RoleData objects that have has_variants=True
        """
        if self._candidate is None:
            self.load()

        return [role for role in self._candidate.roles if role.has_variants]

    def print_enhanced_summary(self) -> None:
        """Log a summary of enhanced role data for debugging."""
        if self._candidate is None:
            self.load()

        self._logger.info("=== CV Loader Enhanced Summary ===")
        self._logger.info(f"Total roles: {len(self._candidate.roles)}")
        self._logger.info(f"Roles with variants: {len(self.get_roles_with_variants())}")
        self._logger.info(f"Total variants: {self.get_total_variants()}")
        self._logger.info(f"Achievement keywords: {len(self.get_all_achievement_keywords())}")

        if self._enhanced_roles:
            self._logger.info("Per-role breakdown:")
            for role_id, enhanced in self._enhanced_roles.items():
                self._logger.info(f"  {role_id}:")
                self._logger.info(f"    Achievements: {enhanced.achievement_count}")
                self._logger.info(f"    Variants: {enhanced.total_variants}")
                self._logger.info(f"    Keywords: {len(enhanced.all_keywords)}")

    # =========================================================================
    # DATA SOURCE PROPERTIES
    # =========================================================================

    @property
    def loaded_from_mongodb(self) -> bool:
        """Check if data was loaded from MongoDB (vs files)."""
        return self._loaded_from_mongodb

    @property
    def is_mongodb_enabled(self) -> bool:
        """Check if MongoDB mode is enabled."""
        return self._use_mongodb

    # =========================================================================
    # SKILLS TAXONOMY METHODS
    # =========================================================================

    def load_skills_taxonomy(self) -> "SkillsTaxonomy":
        """
        Load the role-based skills taxonomy from MongoDB or file.

        The taxonomy defines pre-curated skill sections for each target role.
        This replaces the LLM-generated category approach.

        Returns:
            SkillsTaxonomy instance for generating skills sections

        Raises:
            FileNotFoundError: If taxonomy file doesn't exist (and MongoDB unavailable)
        """
        from src.layer6_v2.skills_taxonomy import SkillsTaxonomy

        # Try MongoDB first if enabled
        if self._use_mongodb and self._mongo_store:
            taxonomy_data = self._mongo_store.get_taxonomy()
            if taxonomy_data:
                self._logger.debug("Loading skills taxonomy from MongoDB")
                return SkillsTaxonomy.from_dict(taxonomy_data)

        # Fall back to file
        taxonomy_path = self.data_path / "role_skills_taxonomy.json"
        return SkillsTaxonomy(taxonomy_path)

    def create_taxonomy_skills_generator(
        self,
        lax_mode: bool = True,
    ) -> "TaxonomyBasedSkillsGenerator":
        """
        Create a taxonomy-based skills generator.

        This is the preferred method for creating a skills generator that
        uses the pre-defined taxonomy instead of LLM-generated categories.

        Args:
            lax_mode: If True, generate 30% more skills for manual pruning

        Returns:
            Configured TaxonomyBasedSkillsGenerator

        Example:
            loader = CVLoader()
            generator = loader.create_taxonomy_skills_generator()
            sections = generator.generate_sections(extracted_jd, bullets, roles)
        """
        from src.layer6_v2.skills_taxonomy import TaxonomyBasedSkillsGenerator

        taxonomy = self.load_skills_taxonomy()
        skill_whitelist = self.get_skill_whitelist()

        return TaxonomyBasedSkillsGenerator(
            taxonomy=taxonomy,
            skill_whitelist=skill_whitelist,
            lax_mode=lax_mode,
        )
